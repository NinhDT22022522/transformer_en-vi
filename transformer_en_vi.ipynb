{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import time"
      ],
      "metadata": {
        "id": "BNsxIz3RydV3"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4W1Zh8OnwSqU"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    \"\"\"\n",
        "    compute sinusoid encoding.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, d_model, max_len, device):\n",
        "        \"\"\"\n",
        "        constructor of sinusoid encoding class\n",
        "\n",
        "        :param d_model: dimension of model\n",
        "        :param max_len: max sequence length\n",
        "        :param device: hardware device setting\n",
        "        \"\"\"\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "\n",
        "        # same size with input matrix (for adding with input matrix)\n",
        "        self.encoding = torch.zeros(max_len, d_model, device=device)\n",
        "        self.encoding.requires_grad = False  # we don't need to compute gradient\n",
        "\n",
        "        pos = torch.arange(0, max_len, device=device)\n",
        "        pos = pos.float().unsqueeze(dim=1)\n",
        "        # 1D => 2D unsqueeze to represent word's position\n",
        "\n",
        "        _2i = torch.arange(0, d_model, step=2, device=device).float()\n",
        "        # 'i' means index of d_model (e.g. embedding size = 50, 'i' = [0,50])\n",
        "        # \"step=2\" means 'i' multiplied with two (same with 2 * i)\n",
        "\n",
        "        self.encoding[:, 0::2] = torch.sin(pos / (10000 ** (_2i / d_model)))\n",
        "        self.encoding[:, 1::2] = torch.cos(pos / (10000 ** (_2i / d_model)))\n",
        "        # compute positional encoding to consider positional information of words\n",
        "\n",
        "    def forward(self, x):\n",
        "        # self.encoding\n",
        "        # [max_len = 512, d_model = 512]\n",
        "\n",
        "        batch_size, seq_len = x.size()\n",
        "        # [batch_size = 128, seq_len = 30]\n",
        "\n",
        "        return self.encoding[:seq_len, :]\n",
        "        # [seq_len = 30, d_model = 512]\n",
        "        # it will add with tok_emb : [128, 30, 512]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ScaleDotProductAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    compute scale dot product attention\n",
        "\n",
        "    Query : given sentence that we focused on (decoder)\n",
        "    Key : every sentence to check relationship with Qeury(encoder)\n",
        "    Value : every sentence same with Key (encoder)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super(ScaleDotProductAttention, self).__init__()\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "\n",
        "    def forward(self, q, k, v, mask=None, e=1e-12):\n",
        "        # input is 4 dimension tensor\n",
        "        # [batch_size, head, length, d_tensor]\n",
        "        batch_size, head, length, d_tensor = k.size()\n",
        "\n",
        "        # 1. dot product Query with Key^T to compute similarity\n",
        "        k_t = k.transpose(2, 3)  # transpose\n",
        "        # Add the print statement here to debug\n",
        "        print(\"Sizes of tensors are q: {}, k: {}, k_t: {}\".format(q.size(), k.size(), k_t.size()))\n",
        "        score = (q @ k_t) / math.sqrt(d_tensor)  # scaled dot product\n",
        "\n",
        "        # 2. apply masking (opt)\n",
        "        if mask is not None:\n",
        "            score = score.masked_fill(mask == 0, -10000)\n",
        "\n",
        "        # 3. pass them softmax to make [0, 1] range\n",
        "        score = self.softmax(score)\n",
        "\n",
        "        # 4. multiply with Value\n",
        "        v = score @ v\n",
        "\n",
        "        return v, score"
      ],
      "metadata": {
        "id": "12dD9z0Iyfb8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, n_head):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.n_head = n_head\n",
        "        self.attention = ScaleDotProductAttention()\n",
        "        self.w_q = nn.Linear(d_model, d_model)\n",
        "        self.w_k = nn.Linear(d_model, d_model)\n",
        "        self.w_v = nn.Linear(d_model, d_model)\n",
        "        self.w_concat = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def forward(self, q, k, v, mask=None):\n",
        "        # 1. dot product with weight matrices\n",
        "        q, k, v = self.w_q(q), self.w_k(k), self.w_v(v)\n",
        "\n",
        "        # 2. split tensor by number of heads\n",
        "        q, k, v = self.split(q), self.split(k), self.split(v)\n",
        "\n",
        "        # 3. do scale dot product to compute similarity\n",
        "        out, attention = self.attention(q, k, v, mask=mask)\n",
        "\n",
        "        # 4. concat and pass to linear layer\n",
        "        out = self.concat(out)\n",
        "        out = self.w_concat(out)\n",
        "\n",
        "        # 5. visualize attention map\n",
        "        # TODO : we should implement visualization\n",
        "\n",
        "        return out\n",
        "\n",
        "    def split(self, tensor):\n",
        "        \"\"\"\n",
        "        split tensor by number of head\n",
        "\n",
        "        :param tensor: [batch_size, length, d_model]\n",
        "        :return: [batch_size, head, length, d_tensor]\n",
        "        \"\"\"\n",
        "        batch_size, length, d_model = tensor.size()\n",
        "\n",
        "        d_tensor = d_model // self.n_head\n",
        "        tensor = tensor.view(batch_size, length, self.n_head, d_tensor).transpose(1, 2)\n",
        "        # it is similar with group convolution (split by number of heads)\n",
        "\n",
        "        return tensor\n",
        "\n",
        "    def concat(self, tensor):\n",
        "        \"\"\"\n",
        "        inverse function of self.split(tensor : torch.Tensor)\n",
        "\n",
        "        :param tensor: [batch_size, head, length, d_tensor]\n",
        "        :return: [batch_size, length, d_model]\n",
        "        \"\"\"\n",
        "        batch_size, head, length, d_tensor = tensor.size()\n",
        "        d_model = head * d_tensor\n",
        "\n",
        "        tensor = tensor.transpose(1, 2).contiguous().view(batch_size, length, d_model)\n",
        "        return tensor"
      ],
      "metadata": {
        "id": "eyxk7AHDyg3j"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, d_model, eps=1e-12):\n",
        "        super(LayerNorm, self).__init__()\n",
        "        self.gamma = nn.Parameter(torch.ones(d_model))\n",
        "        self.beta = nn.Parameter(torch.zeros(d_model))\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(-1, keepdim=True)\n",
        "        var = x.var(-1, unbiased=False, keepdim=True)\n",
        "        # '-1' means last dimension.\n",
        "\n",
        "        out = (x - mean) / torch.sqrt(var + self.eps)\n",
        "        out = self.gamma * out + self.beta\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "joX6D3YjyjF7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionwiseFeedForward(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, hidden, drop_prob=0.1):\n",
        "        super(PositionwiseFeedForward, self).__init__()\n",
        "        self.linear1 = nn.Linear(d_model, hidden)\n",
        "        self.linear2 = nn.Linear(hidden, d_model)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(p=drop_prob)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.linear2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "uMSYp8o44V4M"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "class TransformerEmbedding(nn.Module):\n",
        "    \"\"\"\n",
        "    token embedding + positional encoding (sinusoid)\n",
        "    positional encoding can give positional information to network\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, vocab_size, d_model, max_len, drop_prob, device):\n",
        "        \"\"\"\n",
        "        class for word embedding that included positional information\n",
        "\n",
        "        :param vocab_size: size of vocabulary\n",
        "        :param d_model: dimensions of model\n",
        "        \"\"\"\n",
        "        super(TransformerEmbedding, self).__init__()\n",
        "        self.tok_emb = TokenEmbedding(vocab_size, d_model)\n",
        "        self.pos_emb = PositionalEncoding(d_model, max_len, device)\n",
        "        self.drop_out = nn.Dropout(p=drop_prob)\n",
        "\n",
        "    def forward(self, x):\n",
        "        tok_emb = self.tok_emb(x)\n",
        "        pos_emb = self.pos_emb(x)\n",
        "        return self.drop_out(tok_emb + pos_emb)"
      ],
      "metadata": {
        "id": "S1TX--K54XfJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, ffn_hidden, n_head, drop_prob):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.attention = MultiHeadAttention(d_model=d_model, n_head=n_head)\n",
        "        self.norm1 = LayerNorm(d_model=d_model)\n",
        "        self.dropout1 = nn.Dropout(p=drop_prob)\n",
        "\n",
        "        self.ffn = PositionwiseFeedForward(d_model=d_model, hidden=ffn_hidden, drop_prob=drop_prob)\n",
        "        self.norm2 = LayerNorm(d_model=d_model)\n",
        "        self.dropout2 = nn.Dropout(p=drop_prob)\n",
        "\n",
        "    def forward(self, x, src_mask):\n",
        "        # 1. compute self attention\n",
        "        _x = x\n",
        "        x = self.attention(q=x, k=x, v=x, mask=src_mask)\n",
        "\n",
        "        # 2. add and norm\n",
        "        x = self.dropout1(x)\n",
        "        x = self.norm1(x + _x)\n",
        "\n",
        "        # 3. positionwise feed forward network\n",
        "        _x = x\n",
        "        x = self.ffn(x)\n",
        "\n",
        "        # 4. add and norm\n",
        "        x = self.dropout2(x)\n",
        "        x = self.norm2(x + _x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "l-feVIcr4ZSF"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "\n",
        "    def __init__(self, enc_voc_size, max_len, d_model, ffn_hidden, n_head, n_layers, drop_prob, device):\n",
        "        super().__init__()\n",
        "        self.emb = TransformerEmbedding(d_model=d_model,\n",
        "                                        max_len=max_len,\n",
        "                                        vocab_size=enc_voc_size,\n",
        "                                        drop_prob=drop_prob,\n",
        "                                        device=device)\n",
        "\n",
        "        self.layers = nn.ModuleList([EncoderLayer(d_model=d_model,\n",
        "                                                  ffn_hidden=ffn_hidden,\n",
        "                                                  n_head=n_head,\n",
        "                                                  drop_prob=drop_prob)\n",
        "                                     for _ in range(n_layers)])\n",
        "\n",
        "    def forward(self, x, src_mask):\n",
        "        x = self.emb(x)\n",
        "\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, src_mask)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "qd1qJqI14ajn"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, ffn_hidden, n_head, drop_prob):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        self.self_attention = MultiHeadAttention(d_model=d_model, n_head=n_head)\n",
        "        self.norm1 = LayerNorm(d_model=d_model)\n",
        "        self.dropout1 = nn.Dropout(p=drop_prob)\n",
        "\n",
        "        self.enc_dec_attention = MultiHeadAttention(d_model=d_model, n_head=n_head)\n",
        "        self.norm2 = LayerNorm(d_model=d_model)\n",
        "        self.dropout2 = nn.Dropout(p=drop_prob)\n",
        "\n",
        "        self.ffn = PositionwiseFeedForward(d_model=d_model, hidden=ffn_hidden, drop_prob=drop_prob)\n",
        "        self.norm3 = LayerNorm(d_model=d_model)\n",
        "        self.dropout3 = nn.Dropout(p=drop_prob)\n",
        "\n",
        "    def forward(self, dec, enc, trg_mask, src_mask):\n",
        "        # 1. compute self attention\n",
        "        _x = dec\n",
        "        x = self.self_attention(q=dec, k=dec, v=dec, mask=trg_mask)\n",
        "\n",
        "        # 2. add and norm\n",
        "        x = self.dropout1(x)\n",
        "        x = self.norm1(x + _x)\n",
        "\n",
        "        if enc is not None:\n",
        "            # 3. compute encoder - decoder attention\n",
        "            _x = x\n",
        "            x = self.enc_dec_attention(q=x, k=enc, v=enc, mask=src_mask)\n",
        "\n",
        "            # 4. add and norm\n",
        "            x = self.dropout2(x)\n",
        "            x = self.norm2(x + _x)\n",
        "\n",
        "        # 5. positionwise feed forward network\n",
        "        _x = x\n",
        "        x = self.ffn(x)\n",
        "\n",
        "        # 6. add and norm\n",
        "        x = self.dropout3(x)\n",
        "        x = self.norm3(x + _x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "J9GghZCb4cEq"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, dec_voc_size, max_len, d_model, ffn_hidden, n_head, n_layers, drop_prob, device):\n",
        "        super().__init__()\n",
        "        self.emb = TransformerEmbedding(d_model=d_model,\n",
        "                                        drop_prob=drop_prob,\n",
        "                                        max_len=max_len,\n",
        "                                        vocab_size=dec_voc_size,\n",
        "                                        device=device)\n",
        "\n",
        "        self.layers = nn.ModuleList([DecoderLayer(d_model=d_model,\n",
        "                                                  ffn_hidden=ffn_hidden,\n",
        "                                                  n_head=n_head,\n",
        "                                                  drop_prob=drop_prob)\n",
        "                                     for _ in range(n_layers)])\n",
        "\n",
        "        self.linear = nn.Linear(d_model, dec_voc_size)\n",
        "\n",
        "    def forward(self, trg, src, trg_mask, src_mask):\n",
        "        trg = self.emb(trg)\n",
        "\n",
        "        for layer in self.layers:\n",
        "            trg = layer(trg, src, trg_mask, src_mask)\n",
        "\n",
        "        # pass to LM head\n",
        "        output = self.linear(trg)\n",
        "        return output"
      ],
      "metadata": {
        "id": "mHPY6gzF4dfB"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(nn.Module):\n",
        "\n",
        "    def __init__(self, src_pad_idx, trg_pad_idx, trg_sos_idx, enc_voc_size, dec_voc_size, d_model, n_head, max_len,\n",
        "                 ffn_hidden, n_layers, drop_prob, device):\n",
        "        super().__init__()\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "        self.trg_pad_idx = trg_pad_idx\n",
        "        self.trg_sos_idx = trg_sos_idx\n",
        "        self.device = device\n",
        "        self.encoder = Encoder(d_model=d_model,\n",
        "                               n_head=n_head,\n",
        "                               max_len=max_len,\n",
        "                               ffn_hidden=ffn_hidden,\n",
        "                               enc_voc_size=enc_voc_size,\n",
        "                               drop_prob=drop_prob,\n",
        "                               n_layers=n_layers,\n",
        "                               device=device)\n",
        "\n",
        "        self.decoder = Decoder(d_model=d_model,\n",
        "                               n_head=n_head,\n",
        "                               max_len=max_len,\n",
        "                               ffn_hidden=ffn_hidden,\n",
        "                               dec_voc_size=dec_voc_size,\n",
        "                               drop_prob=drop_prob,\n",
        "                               n_layers=n_layers,\n",
        "                               device=device)\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "        src_mask = self.make_src_mask(src)\n",
        "        trg_mask = self.make_trg_mask(trg)\n",
        "        enc_src = self.encoder(src, src_mask)\n",
        "        output = self.decoder(trg, enc_src, trg_mask, src_mask)\n",
        "        return output\n",
        "\n",
        "    def make_src_mask(self, src):\n",
        "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "        return src_mask\n",
        "\n",
        "    def make_trg_mask(self, trg):\n",
        "        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(3)\n",
        "        trg_len = trg.shape[1]\n",
        "        trg_sub_mask = torch.tril(torch.ones(trg_len, trg_len)).type(torch.ByteTensor).to(self.device)\n",
        "        trg_mask = trg_pad_mask & trg_sub_mask\n",
        "        return trg_mask"
      ],
      "metadata": {
        "id": "RJ8XXIsX4e9m"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TokenEmbedding(nn.Embedding):\n",
        "    \"\"\"\n",
        "    Token Embedding using torch.nn\n",
        "    they will dense representation of word using weighted matrix\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, vocab_size, d_model):\n",
        "        \"\"\"\n",
        "        class for token embedding that included positional information\n",
        "\n",
        "        :param vocab_size: size of vocabulary\n",
        "        :param d_model: dimensions of model\n",
        "        \"\"\"\n",
        "        super(TokenEmbedding, self).__init__(vocab_size, d_model, padding_idx=1)"
      ],
      "metadata": {
        "id": "ouG3TU20fg52"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchtext==0.6.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TaXQruCdIeMh",
        "outputId": "b7d85545-31d2-4baf-9bd7-397d35c43ced"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchtext==0.6.0\n",
            "  Downloading torchtext-0.6.0-py3-none-any.whl (64 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/64.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (4.66.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (2.31.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (2.3.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (1.25.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (1.16.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from torchtext==0.6.0) (0.1.99)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.6.0) (2024.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->torchtext==0.6.0)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->torchtext==0.6.0)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->torchtext==0.6.0)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->torchtext==0.6.0)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->torchtext==0.6.0)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->torchtext==0.6.0)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->torchtext==0.6.0)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->torchtext==0.6.0)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->torchtext==0.6.0)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->torchtext==0.6.0)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->torchtext==0.6.0)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchtext==0.6.0) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->torchtext==0.6.0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchtext==0.6.0) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchtext==0.6.0) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchtext\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.18.0\n",
            "    Uninstalling torchtext-0.18.0:\n",
            "      Successfully uninstalled torchtext-0.18.0\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 torchtext-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_sm\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qef7N7aEL8I4",
        "outputId": "bbd0ebed-e5a9-41fb-d799-f9ef752578ca"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-sm==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.7.1) (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.7.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.25.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install underthesea"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73BgcO3FM3XA",
        "outputId": "0ff4b2cc-a464-406e-c9da-0e646daf734e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting underthesea\n",
            "  Downloading underthesea-6.8.0-py3-none-any.whl (20.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.9/20.9 MB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click>=6.0 in /usr/local/lib/python3.10/dist-packages (from underthesea) (8.1.7)\n",
            "Collecting python-crfsuite>=0.9.6 (from underthesea)\n",
            "  Downloading python_crfsuite-0.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from underthesea) (3.8.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from underthesea) (4.66.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from underthesea) (2.31.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from underthesea) (1.4.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from underthesea) (1.2.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from underthesea) (6.0.1)\n",
            "Collecting underthesea-core==1.0.4 (from underthesea)\n",
            "  Downloading underthesea_core-1.0.4-cp310-cp310-manylinux2010_x86_64.whl (657 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m657.8/657.8 kB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->underthesea) (2023.12.25)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->underthesea) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->underthesea) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->underthesea) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->underthesea) (2024.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->underthesea) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->underthesea) (1.11.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->underthesea) (3.5.0)\n",
            "Installing collected packages: underthesea-core, python-crfsuite, underthesea\n",
            "Successfully installed python-crfsuite-0.9.10 underthesea-6.8.0 underthesea-core-1.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.data import Field, BucketIterator\n",
        "from torchtext.datasets import TranslationDataset\n",
        "from underthesea import word_tokenize\n",
        "\n",
        "class EnViDataLoader:\n",
        "    def __init__(self, ext, tokenize_en, tokenize_vi, init_token, eos_token):\n",
        "        self.ext = ext\n",
        "        self.tokenize_en = tokenize_en\n",
        "        self.tokenize_vi = tokenize_vi\n",
        "        self.init_token = init_token\n",
        "        self.eos_token = eos_token\n",
        "        self.source = None\n",
        "        self.target = None\n",
        "        print('Dataset initializing start')\n",
        "\n",
        "    def make_dataset(self):\n",
        "        if self.ext == ('.en', '.vi'):\n",
        "            self.source = Field(tokenize=self.tokenize_en, init_token=self.init_token, eos_token=self.eos_token,\n",
        "                                lower=True, batch_first=True)\n",
        "            self.target = Field(tokenize=self.tokenize_vi, init_token=self.init_token, eos_token=self.eos_token,\n",
        "                                lower=True, batch_first=True)\n",
        "\n",
        "        elif self.ext == ('.vi', '.en'):\n",
        "            self.source = Field(tokenize=self.tokenize_vi, init_token=self.init_token, eos_token=self.eos_token,\n",
        "                                lower=True, batch_first=True)\n",
        "            self.target = Field(tokenize=self.tokenize_en, init_token=self.init_token, eos_token=self.eos_token,\n",
        "                                lower=True, batch_first=True)\n",
        "\n",
        "        train_data, valid_data, test_data = TranslationDataset.splits(\n",
        "            path='', exts=self.ext, fields=(self.source, self.target))\n",
        "        return train_data, valid_data, test_data\n",
        "\n",
        "    def build_vocab(self, train_data, min_freq):\n",
        "        self.source.build_vocab(train_data, min_freq=min_freq)\n",
        "        self.target.build_vocab(train_data, min_freq=min_freq)\n",
        "\n",
        "    def make_iter(self, train, validate, test, batch_size, device):\n",
        "        train_iterator, valid_iterator, test_iterator = BucketIterator.splits((train, validate, test),\n",
        "                                                                              batch_size=batch_size,\n",
        "                                                                              device=device)\n",
        "        print('Dataset initializing done')\n",
        "        return train_iterator, valid_iterator, test_iterator\n",
        "\n",
        "# Tokenization functions\n",
        "def tokenize_en(text):\n",
        "    return text.split()  # Just a simple tokenization for example\n",
        "\n",
        "def tokenize_vi(text):\n",
        "    return word_tokenize(text, format=\"text\").split()\n",
        "\n",
        "# Initialize DataLoader\n",
        "dataloader = EnViDataLoader(ext=('.en', '.vi'),\n",
        "                            tokenize_en=tokenize_en,\n",
        "                            tokenize_vi=tokenize_vi,\n",
        "                            init_token='<sos>',\n",
        "                            eos_token='<eos>')\n",
        "\n",
        "# Make dataset\n",
        "train_data, valid_data, test_data = dataloader.make_dataset()\n",
        "\n",
        "# Build vocab\n",
        "dataloader.build_vocab(train_data, min_freq=2)\n",
        "\n",
        "# Make iterators\n",
        "train_iterator, valid_iterator, test_iterator = dataloader.make_iter(train_data, valid_data, test_data,\n",
        "                                                                      batch_size=32, device=None)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cJEOYNK_VWO",
        "outputId": "e8a51e21-4755-4714-917f-5fcf665ee9fe"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset initializing start\n",
            "Dataset initializing done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lấy các chỉ số cần thiết\n",
        "src_pad_idx = dataloader.source.vocab.stoi['<pad>']\n",
        "trg_pad_idx = dataloader.target.vocab.stoi['<pad>']\n",
        "trg_sos_idx = dataloader.target.vocab.stoi['<sos>']\n",
        "\n",
        "enc_voc_size = len(dataloader.source.vocab)\n",
        "dec_voc_size = len(dataloader.target.vocab)"
      ],
      "metadata": {
        "id": "pg7UHuz3_YzW"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model parameter setting\n",
        "batch_size = 128\n",
        "max_len = 256\n",
        "d_model = 512\n",
        "n_layers = 6\n",
        "n_heads = 8\n",
        "ffn_hidden = 2048\n",
        "drop_prob = 0.1\n",
        "\n",
        "# optimizer parameter setting\n",
        "init_lr = 1e-5\n",
        "factor = 0.9\n",
        "adam_eps = 5e-9\n",
        "patience = 10\n",
        "warmup = 100\n",
        "epoch = 1000\n",
        "clip = 1.0\n",
        "weight_decay = 5e-4\n",
        "inf = float('inf')"
      ],
      "metadata": {
        "id": "pQOckUrQBG2D"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from collections import Counter\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def bleu_stats(hypothesis, reference):\n",
        "    \"\"\"Compute statistics for BLEU.\"\"\"\n",
        "    stats = []\n",
        "    stats.append(len(hypothesis))\n",
        "    stats.append(len(reference))\n",
        "    for n in range(1, 5):\n",
        "        s_ngrams = Counter(\n",
        "            [tuple(hypothesis[i:i + n]) for i in range(len(hypothesis) + 1 - n)]\n",
        "        )\n",
        "        r_ngrams = Counter(\n",
        "            [tuple(reference[i:i + n]) for i in range(len(reference) + 1 - n)]\n",
        "        )\n",
        "\n",
        "        stats.append(max([sum((s_ngrams & r_ngrams).values()), 0]))\n",
        "        stats.append(max([len(hypothesis) + 1 - n, 0]))\n",
        "    return stats\n",
        "\n",
        "\n",
        "def bleu(stats):\n",
        "    \"\"\"Compute BLEU given n-gram statistics.\"\"\"\n",
        "    if len(list(filter(lambda x: x == 0, stats))) > 0:\n",
        "        return 0\n",
        "    (c, r) = stats[:2]\n",
        "    log_bleu_prec = sum(\n",
        "        [math.log(float(x) / y) for x, y in zip(stats[2::2], stats[3::2])]\n",
        "    ) / 4.\n",
        "    return math.exp(min([0, 1 - float(r) / c]) + log_bleu_prec)\n",
        "\n",
        "\n",
        "def get_bleu(hypotheses, reference):\n",
        "    \"\"\"Get validation BLEU score for dev set.\"\"\"\n",
        "    stats = np.array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
        "    for hyp, ref in zip(hypotheses, reference):\n",
        "        stats += np.array(bleu_stats(hyp, ref))\n",
        "    return 100 * bleu(stats)"
      ],
      "metadata": {
        "id": "OqalcjoRBlmt"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def idx_to_word(x, vocab):\n",
        "    words = []\n",
        "    for i in x:\n",
        "        word = vocab.itos[i]\n",
        "        if '<' not in word:\n",
        "            words.append(word)\n",
        "    words = \" \".join(words)\n",
        "    return words"
      ],
      "metadata": {
        "id": "VowQDSmCBV5M"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "yeF9kmNJBaVZ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import"
      ],
      "metadata": {
        "id": "SRzoGLnuC4eI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "def initialize_weights(m):\n",
        "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
        "        nn.init.kaiming_uniform(m.weight.data)\n",
        "\n",
        "\n",
        "model = Transformer(src_pad_idx=src_pad_idx,\n",
        "                    trg_pad_idx=trg_pad_idx,\n",
        "                    trg_sos_idx=trg_sos_idx,\n",
        "                    d_model=d_model,\n",
        "                    enc_voc_size=enc_voc_size,\n",
        "                    dec_voc_size=dec_voc_size,\n",
        "                    max_len=max_len,\n",
        "                    ffn_hidden=ffn_hidden,\n",
        "                    n_head=n_heads,\n",
        "                    n_layers=n_layers,\n",
        "                    drop_prob=drop_prob,\n",
        "                    device=device).to(device)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')\n",
        "model.apply(initialize_weights)\n",
        "optimizer = Adam(params=model.parameters(),\n",
        "                 lr=init_lr,\n",
        "                 weight_decay=weight_decay,\n",
        "                 eps=adam_eps)\n",
        "\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n",
        "                                                 verbose=True,\n",
        "                                                 factor=factor,\n",
        "                                                 patience=patience)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=src_pad_idx)\n",
        "\n",
        "\n",
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    for i, batch in enumerate(iterator):\n",
        "        src = batch.src\n",
        "        trg = batch.trg\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(src, trg[:, :-1])\n",
        "        output_reshape = output.contiguous().view(-1, output.shape[-1])\n",
        "        trg = trg[:, 1:].contiguous().view(-1)\n",
        "\n",
        "        loss = criterion(output_reshape, trg)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        print('step :', round((i / len(iterator)) * 100, 2), '% , loss :', loss.item())\n",
        "\n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "\n",
        "def evaluate(model, iterator, criterion):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    batch_bleu = []\n",
        "    with torch.no_grad():\n",
        "        for i, batch in enumerate(iterator):\n",
        "            src = batch.src\n",
        "            trg = batch.trg\n",
        "            output = model(src, trg[:, :-1])\n",
        "            output_reshape = output.contiguous().view(-1, output.shape[-1])\n",
        "            trg = trg[:, 1:].contiguous().view(-1)\n",
        "\n",
        "            loss = criterion(output_reshape, trg)\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "            total_bleu = []\n",
        "            for j in range(batch_size):\n",
        "                try:\n",
        "                    trg_words = idx_to_word(batch.trg[j], dataloader.target.vocab)\n",
        "                    output_words = output[j].max(dim=1)[1]\n",
        "                    output_words = idx_to_word(output_words, dataloader.target.vocab)\n",
        "                    bleu = get_bleu(hypotheses=output_words.split(), reference=trg_words.split())\n",
        "                    total_bleu.append(bleu)\n",
        "                except:\n",
        "                    pass\n",
        "\n",
        "            total_bleu = sum(total_bleu) / len(total_bleu)\n",
        "            batch_bleu.append(total_bleu)\n",
        "\n",
        "    batch_bleu = sum(batch_bleu) / len(batch_bleu)\n",
        "    return epoch_loss / len(iterator), batch_bleu\n",
        "\n",
        "\n",
        "def run(total_epoch, best_loss):\n",
        "    train_losses, test_losses, bleus = [], [], []\n",
        "    for step in range(total_epoch):\n",
        "        start_time = time.time()\n",
        "        train_loss = train(model, train_iterator, optimizer, criterion, clip)\n",
        "        valid_loss, bleu = evaluate(model, valid_iterator, criterion)\n",
        "        end_time = time.time()\n",
        "\n",
        "        if step > warmup:\n",
        "            scheduler.step(valid_loss)\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        test_losses.append(valid_loss)\n",
        "        bleus.append(bleu)\n",
        "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "        if valid_loss < best_loss:\n",
        "            best_loss = valid_loss\n",
        "            torch.save(model.state_dict(), 'saved/model-{0}.pt'.format(valid_loss))\n",
        "\n",
        "\n",
        "\n",
        "        print(f'Epoch: {step + 1} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "        print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
        "        print(f'\\tVal Loss: {valid_loss:.3f} |  Val PPL: {math.exp(valid_loss):7.3f}')\n",
        "        print(f'\\tBLEU Score: {bleu:.3f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "WqphPHS-ABGY",
        "outputId": "c1141375-0955-4e85-cba0-2acece8156e0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 81,510,186 trainable parameters\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-585987cabcb3>:7: UserWarning: nn.init.kaiming_uniform is now deprecated in favor of nn.init.kaiming_uniform_.\n",
            "  nn.init.kaiming_uniform(m.weight.data)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Adam' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-585987cabcb3>\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'The model has {count_parameters(model):,} trainable parameters'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitialize_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m optimizer = Adam(params=model.parameters(),\n\u001b[0m\u001b[1;32m     26\u001b[0m                  \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit_lr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                  \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Adam' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run(total_epoch=epoch, best_loss=inf)"
      ],
      "metadata": {
        "id": "f75PRAxmAtVl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}